{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.linalg import svd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistic \n",
    "\n",
    "def std(a):\n",
    "    ar = np.array(a)\n",
    "    std = np.std(ar)\n",
    "    print(\"std is:\",std)\n",
    "    return std\n",
    "\n",
    "def variance(a):\n",
    "    ar = np.array(a)\n",
    "    v = np.var(ar)\n",
    "    print(\"var is:\",v)\n",
    "    return v\n",
    "\n",
    "def mode(a):\n",
    "    return stats.mode(a)[0][0]\n",
    "\n",
    "def stat(data):\n",
    "    n = len(data)\n",
    "    q1 = math.floor(n*0.25)\n",
    "    q3 = math.floor(n*0.75)\n",
    "    q1_value=data[q1]\n",
    "    q3_value=data[q3]\n",
    "    iqr=q3_value-q1_value\n",
    "    result ={\n",
    "        \"median\":np.median(data),\n",
    "        \"mode\":mode(data),\n",
    "        \"MIN\":np.min(data),\n",
    "        \"MAX\":np.max(data),\n",
    "        \"Q1\":q1_value,\n",
    "        \"Q3\":q3_value,\n",
    "        \"IQR\":iqr,\n",
    "    }\n",
    "\n",
    "    return result\n",
    "    \n",
    "def outlier_det(data):\n",
    "    sta = stat(data)\n",
    "    iqr = sta[\"IQR\"]\n",
    "    min_edge = sta[\"Q1\"]-1.5*iqr\n",
    "    max_edge = sta[\"Q3\"]+1.5*iqr\n",
    "    result=[]\n",
    "    print(\"最小边缘是:\",min_edge)\n",
    "    print(\"最大边缘是:\",max_edge)\n",
    "    for i in data:\n",
    "        if i < min_edge or i > max_edge:\n",
    "            result.append(i)\n",
    "    print(\"outliers 有:\",result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std is: 1527.9797846248562\n",
      "[-0.927, -0.731, -0.6, -0.469, 0.971, 1.756]\n",
      "[0.01, 0.04, 0.06, 0.08, 0.3, 0.42]\n"
     ]
    }
   ],
   "source": [
    "# normalization: min-max,z-score,decimal scaling\n",
    "def min_max(v,o_min,o_max,n_min,n_max):\n",
    "    result = (((v-o_min)*(n_max-n_min))/(o_max-o_min))+n_min\n",
    "    return result\n",
    "\n",
    "def z_score(data,m=None,s=None):\n",
    "    if m:\n",
    "        me = m\n",
    "    else:\n",
    "        me = np.mean(data)\n",
    "    if s:\n",
    "        st = s\n",
    "    else:\n",
    "        st = std(data)\n",
    "    result =[]\n",
    "    for i in data:\n",
    "        result.append(round((i-me)/st,3))\n",
    "\n",
    "    return result\n",
    "\n",
    "def decimal_scaling(data):\n",
    "    result=[]\n",
    "    maximum = np.max(data)\n",
    "    bits = round(np.log10(maximum))\n",
    "    for d in data:\n",
    "        result.append(d/(10**bits))\n",
    "    return result\n",
    "\n",
    "data = [100,400,600,800,3000,4200]\n",
    "\n",
    "# min_max(73000,12000,98000,0,1)\n",
    "print(z_score(data))\n",
    "print(decimal_scaling(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[8, 10, 15, 35, 50, 52, 85, 89],\n",
       " [8, 10, 15, 35, 50, 52, 85, 89, 92, 158],\n",
       " [8, 10, 15, 35, 50, 52, 85, 89, 92, 158, 201, 251]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binning equal-depth,equal-width\n",
    "def equal_depth(data,num):\n",
    "    n = len(data)\n",
    "    each = n//num\n",
    "    result=[]\n",
    "    i=0\n",
    "    while i<=n-4:\n",
    "        result.append(data[i:i+each])\n",
    "        i+=each\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "def equal_width(data,num):\n",
    "    width = (np.max(data)-np.min(data))//num\n",
    "    print(\"width:\",width)\n",
    "    edge=np.min(data)+width\n",
    "    result=[[] for _ in range(num)]\n",
    "    for i in range(num):\n",
    "        for j in data:\n",
    "            if edge>=j:\n",
    "                result[i].append(j)\n",
    "            else:\n",
    "                edge = edge+width\n",
    "                break\n",
    "            \n",
    "    return result\n",
    "\n",
    "data = [8, 10, 15, 35, 50, 52, 85, 89, 92, 158, 201, 251]    \n",
    "equal_width(data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "分子: 14\n",
      "分母: -0.811\n",
      "Extend Jaccard: -17.263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-17.263"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distance & similarity\n",
    "def Euclidean(x,y):\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    distance = np.linalg.norm(np.subtract(x,y))\n",
    "    return distance\n",
    "\n",
    "def Manhattan(x,y):\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    distance = np.linalg.norm(np.subtract(x,y),ord=1)\n",
    "    return distance\n",
    "    \n",
    "def Supremum(x,y):\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    distance = np.linalg.norm(np.subtract(x,y),ord=np.inf)\n",
    "    return distance\n",
    "\n",
    "def Minkowski(x,y,o):\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    distance = np.linalg.norm(np.subtract(x,y),ord=o)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def sim_mat(data):\n",
    "    sm = [[0 for _ in range(len(data))] for _ in range(len(data))]\n",
    "    dm = dis_mat(data,data)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i):\n",
    "            sm[i][j]=1-dm[i][j]\n",
    "    return sm\n",
    "            \n",
    "\n",
    "def dis_mat(data1,data2, dis_type=2,s=False):\n",
    "    dm = [[0 for _ in range(len(data2))] for _ in range(len(data1))]\n",
    "    for i in range(len(data1)):\n",
    "        for j in range(i):\n",
    "            if dis_type==1:\n",
    "                dm[i][j]=round(Manhattan(data1[i],data2[j]),3)\n",
    "            elif dis_type==2:\n",
    "                dm[i][j]=round(Euclidean(data1[i],data2[j]),3)\n",
    "            elif dis_type==3:\n",
    "                dm[i][j]=round(Supremum(data1[i],data2[j]),3)\n",
    "                \n",
    "            if s:\n",
    "                dm[j][i]=dm[i][j]\n",
    "    return dm\n",
    "\n",
    "def print_dm(dm):\n",
    "    for i in dm:\n",
    "        print(i)\n",
    "    return True\n",
    "\n",
    "def SMC(x,y):\n",
    "    l = len(x)\n",
    "    f_11=f_01=f_10=f_00=0\n",
    "    for i in range(l):\n",
    "        if x[i]==y[i] and x[i]==1:\n",
    "            f_11+=1\n",
    "        elif x[i]==y[i] and x[i]==0:\n",
    "            f_00+=1\n",
    "        else:\n",
    "            if x[i]==0:\n",
    "                f_01+=1\n",
    "            else:\n",
    "                f_10+=1\n",
    "    similarity = (f_11+f_00)/(f_11+f_01+f_10+f_00)\n",
    "    return similarity\n",
    "\n",
    "def Jaccard(x,y):\n",
    "    l = len(x)\n",
    "    f_11=f_01=f_10=f_00=0\n",
    "    for i in range(l):\n",
    "        if x[i]==y[i] and x[i]==1:\n",
    "            f_11+=1\n",
    "        elif x[i]==y[i] and x[i]==0:\n",
    "            f_00+=1\n",
    "        else:\n",
    "            if x[i]==0:\n",
    "                f_01+=1\n",
    "            else:\n",
    "                f_10+=1\n",
    "    similarity = (f_11)/(f_11+f_01+f_10)\n",
    "    return similarity\n",
    "    \n",
    "    \n",
    "def L2(v):\n",
    "    return round(np.linalg.norm(v),3)\n",
    "\n",
    "def cos_sim(v1,v2,d=3):\n",
    "    top = dot_product(v1,v2)\n",
    "    print(\"\\n分子:\",top)\n",
    "    bottom = round(L2(v1)*L2(v2),d)\n",
    "    print(\"分母:\",bottom)\n",
    "    result = round(top/bottom,d)\n",
    "    print(\"cosine similarity:\",result)\n",
    "    return result\n",
    "\n",
    "def dot_product(a,b):\n",
    "    a=np.array(a)\n",
    "    b=np.array(b)\n",
    "    result = round(np.dot(a,b),3)\n",
    "    return result\n",
    "\n",
    "def EJ(x,y):\n",
    "    top = dot_product(x,y)\n",
    "    print(\"\\n分子:\",top)\n",
    "    bottom = round(L2(x)+L2(y)-top,3)\n",
    "    print(\"分母:\",bottom)\n",
    "    result = round(top/bottom,3)\n",
    "    print(\"Extend Jaccard:\",result)\n",
    "    return result\n",
    "    \n",
    "def pearson(x,y):\n",
    "    return np.corrcoef(x,y)\n",
    "\n",
    "def correlation(x,y):\n",
    "    n = len(x)\n",
    "    r=0\n",
    "    s_x=0\n",
    "    s_y=0\n",
    "    for i in range(n):\n",
    "        r+=(x[i]-np.mean(x))*(y[i]-np.mean(y))\n",
    "        s_x+=np.square(x[i]-np.mean(x))\n",
    "        s_y+=np.square(y[i]-np.mean(y))\n",
    "    cov = r/(n-1)\n",
    "    print(cov)\n",
    "    std_x = np.sqrt(s_x/(n-1))\n",
    "    print(std_x)\n",
    "    std_y = np.sqrt(s_y/(n-1))\n",
    "    print(std_y)\n",
    "    result = cov/(std_x*std_y)\n",
    "    return result\n",
    "\n",
    "def kevin_mean(x):\n",
    "    r = []\n",
    "    for i in x:\n",
    "        if i != 0:\n",
    "            r.append(i)\n",
    "    result = np.mean(r)\n",
    "    return result\n",
    "    \n",
    "def kevin_pearson(x,y):\n",
    "    \n",
    "    m1 = kevin_mean(x)\n",
    "    m2 = kevin_mean(y)\n",
    "    for i in range(len(x)):\n",
    "        if x[i] !=0:\n",
    "            x[i]=round(np.subtract(x[i],m1),1)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if y[i] !=0:\n",
    "            y[i]=round(np.subtract(y[i],m2),1)\n",
    "\n",
    "    result = round(cos_sim(x,y),2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def item_item(sims,rates):\n",
    "    r = np.dot(sims,rates)\n",
    "    result = r/np.sum(sims)\n",
    "    return round(result,2)\n",
    "\n",
    "\n",
    "\n",
    "# pearson(x,y)\n",
    "# correlation(x,y)\n",
    "# np.mean(x)\n",
    "\n",
    "a = [4,0,0,5,1,0,0]\n",
    "b = [0,0,0,2,4,5,0]\n",
    "EJ(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy\n",
    "\n",
    "def entropy(x):\n",
    "    n = len(x)\n",
    "    r=0\n",
    "    s = np.sum(x)\n",
    "    for i in range(n):\n",
    "        p = x[i]/s\n",
    "        r+=p*np.log2(p)\n",
    "    result=round(-1*r,3)\n",
    "    return result\n",
    "\n",
    "# GINI index最小的切割\n",
    "def gini(x):\n",
    "    n = len(x)\n",
    "    r = 0\n",
    "    s = np.sum(x)\n",
    "    for i in range(n):\n",
    "        p = x[i]/s\n",
    "        r+=np.square(p)\n",
    "        \n",
    "    \n",
    "    result = round(1-r,3)\n",
    "    return result\n",
    "\n",
    "# 输入个数列表，如果是id，则全为1\n",
    "def split_info(x):\n",
    "    r=0\n",
    "    n=len(x)\n",
    "    s = np.sum(x)\n",
    "    for i in range(n):\n",
    "        p = x[i]/s\n",
    "        r+=p*np.log2(p)\n",
    "    result=-1*r\n",
    "    return result\n",
    "\n",
    "\n",
    "def error(x):\n",
    "    s = np.sum(x)\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        x[i]/=s\n",
    "    result = round(1-np.max(x),3)\n",
    "    return result\n",
    "\n",
    "# print(((4/20)*gini([1,3])+(8/20)*gini([1,0])+(8/20)*gini([1,7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "\n",
    "def update_center(a):\n",
    "    m = np.mean(a,axis=0)\n",
    "    x=round(m[0],3)\n",
    "    y=round(m[1],3)\n",
    "    result = [x,y]\n",
    "    return result\n",
    "\n",
    "def cent(x,center,cluster,first=True):\n",
    "    C = center\n",
    "    dm = [0 for _ in range(len(center))]\n",
    "    for i in range(len(C)):\n",
    "        dm[i]=np.around(Euclidean(x,C[i]))\n",
    "    close = np.argmin(dm)\n",
    "    print(\"\\n当前点为:\",x)\n",
    "    print(\"对所有点的距离为\",dm)\n",
    "    print(\"所以最接近的集群为 {}, 中心为 {}\".format(close+1,center[close]))\n",
    "#     if first and dm[close]!=0:\n",
    "    cluster[close].append(x)\n",
    "#     center[close]=update_center(cluster[close])\n",
    "\n",
    "    return cluster\n",
    "\n",
    "\n",
    "def cxm_kmeans(data,center,k=3,first=True):\n",
    "    if first:\n",
    "        cluster = [[center[i]] for i in range(k)]\n",
    "    else:\n",
    "        cluster = [[] for _ in range(k)]\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        x = data[i]\n",
    "        cluster = cent(x,center,cluster,first)\n",
    "\n",
    "    new_center = []\n",
    "    for c in cluster:\n",
    "        new_center.append(update_center(c))\n",
    "    \n",
    "    print(f\"\\n迭代完成后，新的中心为:\\n{new_center}\")\n",
    "    print(f\"\\n结果为:\\n{cluster}\\n\")\n",
    "    return new_center\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "\n",
    "def group_average(dis,size):\n",
    "    return np.sum(dis)/size\n",
    "    \n",
    "def dbscan(data,eps,minpoints):\n",
    "    dm = dis_mat(data,data,2,True)\n",
    "    print_dm(dm)\n",
    "    n=len(data)\n",
    "    count_dict={}\n",
    "    cores = []\n",
    "    boarder=[]\n",
    "    noise = []\n",
    "    for i in range(n):\n",
    "        count_dict[i]=[]\n",
    "        for j in range(n):\n",
    "            if i==j:\n",
    "                continue\n",
    "            if dm[i][j]<=eps:\n",
    "                count_dict[i].append(j+1)\n",
    "#         print(count_dict[i])\n",
    "        if len(count_dict[i])>=minpoints-1:\n",
    "            cores.append(i+1)\n",
    "        elif len(count_dict[i])<minpoints-1 and len(count_dict[i])>0:\n",
    "            boarder.append(i+1)\n",
    "        else:\n",
    "            noise.append(i+1)\n",
    "            \n",
    "    return cores,boarder,noise\n",
    "    \n",
    "def data_plot(data):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in data:\n",
    "        x.append(i[0])\n",
    "        y.append(i[1])\n",
    "\n",
    "    # 生成图形\n",
    "    plt.scatter(x, y) # 颜色绿色，点形圆形，线性虚线，设置图例显示内容，线条宽度为2\n",
    "\n",
    "    plt.ylabel('y') # 横坐标轴的标题\n",
    "    plt.xlabel('x') # 纵坐标轴的标题\n",
    "    plt.xticks(np.arange(0, 11, 1)) # 设置横坐标轴的刻度为 0 到 10 的数组\n",
    "    plt.yticks(np.arange(0, 11, 1))\n",
    "#     plt.ylim([-2, 2]) # 设置纵坐标轴范围为 -2 到 2\n",
    "#     plt.legend() # 显示图例, 图例中内容由 label 定义\n",
    "    plt.grid() # 显示网格\n",
    "    plt.title('CHEN XUMIN 19430019') # 图形的标题\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252.0\n",
      "210.0\n"
     ]
    }
   ],
   "source": [
    "# 排列组合\n",
    "def fac(num):\n",
    "    factorial = 1\n",
    "    for i in range(1,num+1):\n",
    "         factorial = factorial*i\n",
    "    return factorial\n",
    "\n",
    "#括号形式的组合表示，top表示总数，bottom表示取多少个\n",
    "def Combination(top,bottom):\n",
    "    result = fac(top)/(fac(top-bottom)*fac(bottom))\n",
    "    return result\n",
    "\n",
    "print(Combination(10,5))\n",
    "print(Combination(10,4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "def TF(v):\n",
    "    tf = []\n",
    "    for f in v:\n",
    "        tf.append(round(f/np.max(v),3))\n",
    "    print(\"normalized-tf:\",tf)\n",
    "    return tf\n",
    "\n",
    "def IDF(N,DF):\n",
    "    idf = []\n",
    "    for df in DF:\n",
    "        idf.append(round(np.log10(N/df),3))\n",
    "    print(\"IDF:\",idf)\n",
    "    return idf\n",
    "\n",
    "# 这里只计算了一行的tf-idf\n",
    "def TF_IDF(v,df,N):\n",
    "    tf = TF(v)\n",
    "    idf = IDF(N,df)\n",
    "    result=[]\n",
    "    for i in range(len(df)):\n",
    "        result.append(tf[i]*idf[i])\n",
    "    print(\"tf-idf:\",result)\n",
    "    return result\n",
    "\n",
    "def smoothing(f,dj,l):\n",
    "    length=len(f)\n",
    "    top = np.add(l , f)\n",
    "    bottom = length*l+dj\n",
    "    result = top/bottom\n",
    "    return result\n",
    "\n",
    "\n",
    "def str2index(data):\n",
    "    n=len(data)\n",
    "    m = []\n",
    "    vocab={}\n",
    "    for i in range(n):\n",
    "        for j in data[i]:\n",
    "            if j not in m:\n",
    "                m.append(j)\n",
    "                \n",
    "    for i in range(len(m)):\n",
    "        vocab[m[i]]=i\n",
    "    print(vocab)\n",
    "    result=[[0 for _ in range(len(m))]for _ in range(n)]\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in data[i]:\n",
    "            result[i][vocab[j]]+=1\n",
    "            \n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "def Cov_matrix(X):\n",
    "    mean = np.mean(X,axis=1)\n",
    "    cov_m = np.cov(X)\n",
    "    return cov_m\n",
    "\n",
    "def EigDec(X):\n",
    "    val,vec = np.linalg.eig(X)\n",
    "    print(\"eigen value are:\\n\",val)\n",
    "    print(\"max\",max(val))\n",
    "    print(\"eigen vector are:\\n\",vec)\n",
    "    return val,vec\n",
    "\n",
    "def PCA(X):\n",
    "    m = Cov_matrix(X)\n",
    "    val,vec = EigDec(m)\n",
    "    return val,vec\n",
    "\n",
    "def simple_svd(X):\n",
    "    U,s,VT = svd(X)\n",
    "    print(\"\\n X = \\n\",X)\n",
    "    print(\"\\n U = \\n\",U)\n",
    "    print(\"\\n s = \\n\",s)\n",
    "    print(\"\\n VT = \\n\",VT)\n",
    "    recovered_X = U.dot(np.diag(s)).dot(VT)\n",
    "    return recovered_X\n",
    "\n",
    "def kevin_rank(X):\n",
    "    result=np.linalg.matrix_rank(X)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified PageRank by Power Iteration Method\n",
    "# iteration 是迭代次数\n",
    "# init是初始化的值，类型为列表\n",
    "\n",
    "def PageRank_PI(A,r,iteration):\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        A[i]=np.multiply(A[i],1/(np.sum(A[i])))\n",
    "    \n",
    "    M = np.array(A).T\n",
    "\n",
    "    print(M)\n",
    "    print(f\"This iteration 0,new Page Rank is :\\n{r}\")\n",
    "    r= np.array(r)\n",
    "    for i in range(iteration):\n",
    "        r= np.around(np.dot(M,r),4)\n",
    "        print(f\"This iteration{i+1},new Page Rank is :\\n{r}\")\n",
    "        \n",
    "    return r\n",
    "    \n",
    "    \n",
    "# PageRank with Damping Factor\n",
    "def PageRank_DF(A,r,b,S,iteration):\n",
    "    N = len(S)\n",
    "    \n",
    "    for i in range(len(A)):\n",
    "        A[i]=np.multiply(A[i],1/(np.sum(A[i])))\n",
    "    \n",
    "    AT = np.array(A).T\n",
    "    M = []\n",
    "    factor = (1-b)/N\n",
    "    for i in range(len(AT)):\n",
    "        if i+1 in S:\n",
    "            M.append(np.add(np.multiply(AT[i],b),factor))\n",
    "        else:\n",
    "            M.append(np.multiply(AT[i],b))\n",
    "        \n",
    "    print(f\"The Matrix is :\\n{M}\")\n",
    "    print(f\"This iteration 0,new Page Rank is :\\n{r}\")\n",
    "    r = np.array(r)\n",
    "    for i in range(iteration):\n",
    "        r = np.around(np.dot(M,r.T),4)\n",
    "        print(f\"\\nThis iteration {i+1},new Page Rank is :\\n{r}\")\n",
    "        \n",
    "    return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apriori\n",
    "def count_item(data,k=1):\n",
    "    N = len(data)\n",
    "    nums={}\n",
    "    if k==1:\n",
    "        for i in range(N):\n",
    "            for j in data[i]:\n",
    "                if j not in nums:\n",
    "                    nums[j]=1\n",
    "                else:\n",
    "                    nums[j]+=1\n",
    "\n",
    "    elif k==2:\n",
    "        for i in range(N):\n",
    "            s= \" \".join(data[i])\n",
    "            if s not in nums:\n",
    "                nums[s]=1\n",
    "            else:\n",
    "                nums[s]+=1\n",
    "    print(f\"the frequency is :{nums}\")\n",
    "    return nums\n",
    "\n",
    "def transactions():\n",
    "    N = int(input(\"please input your transaction number：\"))\n",
    "    trans=[]\n",
    "    for i in range(N):\n",
    "        trans.append([i for i in input(\"please input the items:\").split()])\n",
    "        \n",
    "    print(f\"The transaction tables is following:\\n{trans}\")\n",
    "    return trans\n",
    "\n",
    "def one_itemset(nums,minsup):\n",
    "    items = nums.keys()\n",
    "    freq = []\n",
    "    for i in items:\n",
    "        if nums[i]>=minsup:\n",
    "            freq.append(i)\n",
    "    return freq\n",
    "\n",
    "def two_itemset(dataset,freq,minsup):\n",
    "    n = len(freq)\n",
    "    candidates=[]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            candidates.append([freq[i],freq[j]])\n",
    "            \n",
    "\n",
    "    frequency={}\n",
    "    for c in candidates:\n",
    "        c.sort()\n",
    "        for d in dataset:\n",
    "            s = \"\".join(d)\n",
    "            if c[0] in s and c[1] in s:\n",
    "                items = \" \".join(c)\n",
    "                if items not in frequency:\n",
    "                    frequency[items]=1\n",
    "                else:\n",
    "                    frequency[items]+=1\n",
    "    print(f\"\\nall possible candidate frequency:\\n{frequency}\")\n",
    "    freq_itemsets = one_itemset(frequency,minsup)\n",
    "    print(f\"\\nall frequent 2-itemsets:\\n{freq_itemsets}\")\n",
    "    itemsets=[]\n",
    "    for i in freq_itemsets:\n",
    "        itemsets.append(i.split())\n",
    "    return itemsets\n",
    "                \n",
    "    \n",
    "def three_itemset(dataset,freq,minsup):\n",
    "    n = len(freq)\n",
    "    freq.sort()\n",
    "    candidates=[]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            temp = freq[i].copy()\n",
    "            temp.extend(freq[j])\n",
    "            itemset=list(set(temp))\n",
    "            if len(itemset)>3:\n",
    "                continue\n",
    "            itemset.sort()\n",
    "            if itemset not in candidates:\n",
    "                candidates.append(itemset)\n",
    "    \n",
    "    frequency ={}\n",
    "    for c in candidates:\n",
    "        c.sort()\n",
    "        for d in dataset:\n",
    "            s = \"\".join(d)\n",
    "            if c[0] in s and c[1] in s and c[2] in s:\n",
    "                items = \" \".join(c)\n",
    "                if items not in frequency:\n",
    "                    frequency[items]=1\n",
    "                else:\n",
    "                    frequency[items]+=1\n",
    "    print(f\"\\n all possible candidate frequency:\\n{frequency}\")\n",
    "    freq_itemsets = one_itemset(frequency,minsup)\n",
    "    print(f\"\\nall frequent 3 itemsets:\\n{freq_itemsets}\")\n",
    "    itemsets=[]\n",
    "    for i in freq_itemsets:\n",
    "        itemsets.append(i.split())\n",
    "    return itemsets\n",
    "    \n",
    "    \n",
    "def count_all(dataset):\n",
    "    cp = dataset.copy()\n",
    "    n = len(dataset)\n",
    "    max_len=0\n",
    "    for i in data:\n",
    "        if len(i)>max_len:\n",
    "            max_len=len(i)\n",
    "    items=[]\n",
    "    for i in cp:\n",
    "        items.extend(i)\n",
    "    items =list(set(items))\n",
    "    frequency={}\n",
    "    for i in items:\n",
    "        frequency[i]=0\n",
    "        for j in dataset:\n",
    "            if i in j:\n",
    "                frequency[i]+=1\n",
    "    \n",
    "    i2 = []  \n",
    "    for i in range(len(items)):\n",
    "        for j in range(i+1,len(items)):\n",
    "            i2.append([items[i],items[j]])\n",
    "            \n",
    "\n",
    "    for c in i2:\n",
    "        c.sort()\n",
    "        its = \" \".join(c)\n",
    "        frequency[its]=0\n",
    "        for d in dataset:\n",
    "            s = \"\".join(d)\n",
    "            if c[0] in s and c[1] in s:\n",
    "                frequency[its]+=1\n",
    "                \n",
    "                \n",
    "                \n",
    "    i3=[]\n",
    "    for i in range(len(i2)):\n",
    "        for j in range(i+1,len(i2)):\n",
    "            temp = i2[i].copy()\n",
    "            temp.extend(i2[j])\n",
    "            its =list(set(temp))\n",
    "            if len(its)>3:\n",
    "                continue\n",
    "            its.sort()\n",
    "            if its not in i3:\n",
    "                i3.append(its)\n",
    "\n",
    "    for c in i3:\n",
    "        c.sort()\n",
    "        its = \" \".join(c)\n",
    "        frequency[its]=0\n",
    "        for d in dataset:\n",
    "            s = \"\".join(d)\n",
    "            if c[0] in s and c[1] in s and c[2] in s:\n",
    "                frequency[its]+=1\n",
    "                \n",
    "    return frequency\n",
    "            \n",
    "            \n",
    "def confidence(top,bottom,frequency):\n",
    "    top_count = frequency[top]\n",
    "    print(top,top_count)\n",
    "    bottom_count = frequency[bottom]\n",
    "    print(bottom,bottom_count)\n",
    "    result = top_count/bottom_count\n",
    "    return result\n",
    "\n",
    "def fp(dataset,threshold):\n",
    "    header = count_item(dataset)\n",
    "    freq_list = one_itemset(header,min_sup)\n",
    "    freq = all_frequency =count_all(dataset)\n",
    "    result = []\n",
    "    for i in range(len(dataset)):\n",
    "        temp=[]\n",
    "        for j in dataset[i]:\n",
    "            if j in freq_list:\n",
    "                temp.append(j)\n",
    "                \n",
    "        result.append(temp)\n",
    "    \n",
    "    print(\"frequent items:\",result)\n",
    "\n",
    "#     for i in range(len(result)):\n",
    "#         for j in range(len(result[i])):\n",
    "#             for k in range(j,len(result[i])):\n",
    "#                 if freq[result[i][j]]>freq[result[i][k]]:\n",
    "#                     result[i][j],result[i][k]=result[i][k],result[i][j]\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'median': 19.0, 'mode': 19, 'MIN': 0, 'MAX': 50, 'Q1': 14, 'Q3': 22, 'IQR': 8}\n",
      "std is: 12.379001147971818\n",
      "12.379001147971818\n",
      "var is: 153.2396694214876\n",
      "153.2396694214876\n",
      "最小边缘是: 2.0\n",
      "最大边缘是: 34.0\n",
      "outliers 有: [0, 50]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据统计相关计算模板\n",
    "a = [0, 5, 14, 16, 17, 19, 19, 19, 22, 30, 50]\n",
    "print(stat(a))\n",
    "print(std(a))\n",
    "print(variance(a))\n",
    "outlier_det(a)\n",
    "mode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相似度计算模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n",
      "0.4\n",
      "0.0\n",
      "-0.08000000000000002\n",
      "0.32\n"
     ]
    }
   ],
   "source": [
    "# 决策树计算模板\n",
    "\n",
    "id3 c4.5\n",
    "total = entropy([4,4])\n",
    "split = 0.5*entropy([1,3])+0.5*entropy([3,1])\n",
    "informationgain = total-split\n",
    "print(informationgain)\n",
    "\n",
    "\n",
    "# CART\n",
    "p = gini([1,4])\n",
    "print(p)\n",
    "s=(4/5)*gini([2,2])+(1/5)*gini([1,0])\n",
    "print(s)\n",
    "w = (2/5)*gini([2,0])+(2/5)*gini([2,0])+(1/5)*gini([1,0])\n",
    "print(w)\n",
    "e = (5/11)*gini([1,4])+(6/11)*gini([5,1])\n",
    "print(e)\n",
    "\n",
    "\n",
    "g1 = p-s\n",
    "print(g1)\n",
    "g2 = p-w\n",
    "print(g2)\n",
    "g3 = p-e\n",
    "print(g3)\n",
    "tiredness = (3/8)*gini([1,2])+(5/8)*gini([2,3])\n",
    "gain_1 = p-fever\n",
    "gain_2 = p-tiredness\n",
    "print(gain_1)\n",
    "print(gain_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please input your transaction number：0\n",
      "The transaction tables is following:\n",
      "[]\n",
      "the frequency is :{}\n",
      "min support is :0\n",
      "\n",
      "all frequent 1 itemsets []\n"
     ]
    }
   ],
   "source": [
    "# Apriori计算模板\n",
    "dataset=transactions()\n",
    "nums=count_item(dataset)\n",
    "min_sup=int(input(\"min support is :\"))\n",
    "freq = one_itemset(nums,min_sup)\n",
    "print(f\"\\nall frequent 1 itemsets {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all possible candidate frequency:\n",
      "{}\n",
      "\n",
      "all frequent 2-itemsets:\n",
      "[]\n",
      "\n",
      " all possible candidate frequency:\n",
      "{}\n",
      "\n",
      "all frequent 3 itemsets:\n",
      "[]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c31154d28711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(\"\\n\",freq2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mthree_itemset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreq2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_sup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_frequency\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcount_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mall_freq_itemsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_itemset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_frequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_sup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-a0608f13d9c1>\u001b[0m in \u001b[0;36mcount_all\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "freq2 = two_itemset(dataset,freq,min_sup)\n",
    "# print(\"\\n\",freq2)\n",
    "three_itemset(dataset,freq2,min_sup)\n",
    "all_frequency =count_all(dataset)\n",
    "all_freq_itemsets = one_itemset(all_frequency,min_sup)\n",
    "\n",
    "print(f\"\\nall items' frequency:\\n{all_frequency}\")\n",
    "print(f\"\\nall the frequency itemsets:\\n{all_freq_itemsets}\")\n",
    "# confidence(\"b c m\",\"b m\",all_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp-tree\n",
    "# dataset=transactions()\n",
    "# dataset=[['f', 'a', 'c', 'd', 'g', 'i', 'm', 'p'], ['a', 'b', 'c', 'f', 'l', 'm', 'o'], ['b', 'f', 'h', 'j', 'o', 'w'], ['b', 'c', 'k', 's', 'p'], ['a', 'f', 'c', 'e', 'l', 'p', 'm', 'n']]\n",
    "fp(dataset,min_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN 判断点计算模板\n",
    "data = [\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [2, 0],\n",
    "    [3, 0],\n",
    "    [1, 1],\n",
    "    [2, 1],\n",
    "    [4, 1],\n",
    "    [6, 0],\n",
    "    [5, 2],\n",
    "    [6, 3],\n",
    "    [7, 3],\n",
    "    [6, 4],\n",
    "    [7, 4]\n",
    "]\n",
    "\n",
    "data_plot(data)\n",
    "# dm = dis_mat(data,data)\n",
    "# dm\n",
    "eps = np.sqrt(2)\n",
    "minpoints=4\n",
    "c,b,n = dbscan(data,eps,minpoints)\n",
    "print(\"core points:\",c)\n",
    "print(\"boarder points:\",b)\n",
    "print(\"noise points:\",n)\n",
    "\n",
    "\n",
    "# k-means\n",
    "\n",
    "center = [[2,10],[5,8],[1,2]]\n",
    "data = [\n",
    "    [2,5],\n",
    "    [8,4],\n",
    "    [7,5],\n",
    "    [6,4],\n",
    "    [4,9]\n",
    "]\n",
    "\n",
    "new_data=[\n",
    "    [2,10],\n",
    "    [2,5],\n",
    "    [8,4],\n",
    "    [5,8],\n",
    "    [7,5],\n",
    "    [6,4],\n",
    "    [1,2],\n",
    "    [4,9]\n",
    "]\n",
    "data_plot(new_data)\n",
    "new_center = cxm_kmeans(data,center,3)\n",
    "# print(new_center)\n",
    "new_center = cxm_kmeans(new_data,new_center,3,first=False)\n",
    "new_center = cxm_kmeans(new_data,new_center,3,first=False)\n",
    "new_center = cxm_kmeans(new_data,new_center,3,first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-item推荐系统计算模板\n",
    "\n",
    "\n",
    "x = [1,0,3,0,0,5,0,0,5,0,4,0]\n",
    "y = [2,4,0,1,2,0,3,0,4,3,5,0]\n",
    "z = [1,0,3,0,3,0,0,2,0,0,4,0]\n",
    "\n",
    "sims=[kevin_pearson(x,y),kevin_pearson(x,z)]\n",
    "print(sims)\n",
    "rates=[2,3]\n",
    "item_item(sims,rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  0.5]\n",
      " [0.5 0.  0.5 0. ]\n",
      " [0.  1.  0.  0.5]\n",
      " [0.5 0.  0.5 0. ]]\n",
      "This iteration 0,new Page Rank is :\n",
      "[0.25, 0.25, 0.25, 0.25]\n",
      "This iteration1,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration2,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration3,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration4,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration5,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration6,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration7,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration8,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration9,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n",
      "This iteration10,new Page Rank is :\n",
      "[0.125 0.25  0.375 0.25 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.125, 0.25 , 0.375, 0.25 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pagerank\n",
    "r = [.25,.25,.25,.25]\n",
    "\n",
    "A = [\n",
    "    [0,1,0,1],\n",
    "    [0,0,1,0],\n",
    "    [0,1,0,1],\n",
    "    [1,0,1,0]\n",
    "]\n",
    "\n",
    "\n",
    "PageRank_PI(A,r,10)\n",
    "# b=0.7\n",
    "# S = [1,2,3,4]\n",
    "# PageRank_DF(A,r,b,S,3)\n",
    "# a = [0,0,1,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= [0,5,7,3,7,2,3,7,1,1,2,5,4,5,10]\n",
    "y= [2,4,9,4,9,1,1,6,0,2,3,5,6,5,12]\n",
    "pearson(x,y)\n",
    "# correlation(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
